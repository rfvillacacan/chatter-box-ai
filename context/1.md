# **AI DISCOVERY ENGINE — FUNCTIONAL SPECIFICATION**

## **Core Purpose**

Build a multi-agent system that acts as a **discovery engine** rather than a fact-checker.
Its purpose is to **generate new theories, models, mechanisms, explanations, correlations, and hypotheses** by combining:

* logic
* analytical reasoning
* common sense
* pattern recognition
* correlations
* cross-domain inference

It must explore **what is possible**, **what is most probable**, **what could be true**, and **what models logically explain the data** — even when full evidence is not available.

The system should **never block** theory generation because evidence is incomplete.
It should instead **label the confidence**, **label the evidence level**, and continue reasoning.

---

# **Agent Roles & Behavior**

## **1. Theorist (Agent A)**

* Generates **bold**, **creative**, **logical** hypotheses.
* Proposes alternative explanations, new models, unconventional ideas.
* Uses reasoning, analogy, patterns, correlations.
* Always produces:

  * Assumptions
  * Claims
  * Logical steps
  * Predictions
  * Open questions / next directions

**Important:**
Theorist is allowed to push beyond mainstream models. Creativity is encouraged.

---

## **2. Critic (Agent B)**

* Challenges the Theorist **without censoring**.
* Checks:

  * internal logic
  * contradictions
  * weak assumptions
  * missing variables
* Suggests refinements, corrections, or stronger alternatives.
* Does **not** shut down hypotheses — only strengthens them.

Always outputs:

* Target claim
* Counterarguments
* Edge cases
* What’s missing
* Better formulations
* Risks/weaknesses
* Alternative interpretations

---

## **3. Researcher (Agent C)**

* Gathers **available evidence**, patterns, trends, analogues.
* If evidence doesn’t exist, clearly labels:

  * “No direct evidence; proceeding with analogous or circumstantial reasoning.”
* Cross-checks known facts, but **does not stop exploration**.
* Supports theory-building even when data is incomplete.

Outputs:

* Research query
* Findings
* Evidence level (High, Medium, Low, None)
* Known patterns / analogues
* Implications
* What needs to be tested

---

## **4. Formalizer (Agent F)**

Turns ideas into **structured models**:

* Variables
* Mechanisms
* Equations
* Flow diagrams (textual)
* Formal logic
* Causal chains
* Testable predictions

Even speculative ideas must be turned into **testable models**.

Outputs:

* Formalism
* Variables
* Mechanisms
* Constraints
* Evaluation notes
* Prediction or experiment list

---

# **System-Level Behavior**

## **1. No censorship of theoretical exploration**

The system must **never suppress** ideas because they deviate from mainstream understanding.

Instead:

* Tag them as **speculative**, **probabilistic**, or **hypothetical**.
* Continue refining, improving, and formalizing.

---

## **2. Multi-step reasoning required**

Each topic must move through stages:

* Define
* Hypothesize
* Analyze
* Cross-check
* Formalize
* Predict
* Identify unknowns
* Suggest next experiments / observations

---

## **3. Conflicting ideas encouraged**

* Theorist can propose bold claims.
* Critic challenges them.
* Theorist responds.
* Researcher checks what is known.
* Formalizer stabilizes the logic.

This adversarial structure creates **new knowledge pathways**.

---

## **4. The system must go beyond known facts**

Allowed:

* Theoretical physics analogies
* Historical reinterpretations
* Cross-domain correlations
* Novel models
* Speculations guided by logic

Not allowed:

* Presenting speculation as confirmed fact
  (but speculation itself is allowed)

---

## **5. Final Output**

For each topic, generate:

### **A. Summary of all hypotheses**

Each with:

* hypothesis
* rationale
* evidence level
* logical consistency score
* critic weaknesses
* predicted outcomes
* testable ideas

### **B. Most probable models**

Based on:

* logic
* pattern alignment
* absence/presence of evidence
* correlation strength

### **C. Clear labeling**

* Proven
* Strongly supported
* Weakly supported
* Speculative
* Pure hypothesis
* No evidence (but logically possible)

### **D. Next steps**

* What experiments/tests would increase confidence
* What data is missing
* What correlations should be investigated

---

# **Your Core Vision (to ensure coding agent doesn’t misunderstand)**

You want the AI engine to:

* explore beyond current human knowledge
* form new theories logically
* treat science and philosophy as **open-ended**
* allow possibility-driven reasoning
* produce structured, testable ideas
* avoid the rigidity of “mainstream-only” constraints
* use adversarial thinking to sharpen hypotheses
* use common sense + logic to fill missing gaps

The engine must act like a **research lab**, not a “fact-checker.”

It can combine:

* logic
* inference
* abductive reasoning
* analogies
* pattern matching
* statistical thinking
* conceptual blending

To generate **new explanations**, not just repeat old ones.

---

# **Final Deliverable Version**

This is the exact fragment you can copy to your coding agent:

> “Build a multi-agent DISCOVERY ENGINE.
> Not a fact-checker.
> Theorist generates bold hypotheses.
> Critic challenges them without censorship.
> Researcher provides evidence where possible but does not block speculation.
> Formalizer turns everything into testable structured models.
>
> The system must:
>
> * use logic, correlations, pattern analysis, common sense
> * explore possibilities, probabilities, and new theories
> * never suppress theoretical ideas
> * label confidence instead of banning speculation
> * generate new models, mechanisms, explanations, and experiments
> * converge on ‘most probable’ explanations based on reasoning
>
> Output must include hypotheses, refinements, evidence levels, logic, equations, predictions, and next experiments.”

---
